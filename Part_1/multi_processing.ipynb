{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You have a Python script that processes millions of records in a single thread. How would you optimize it to leverage multiple cores and reduce the execution time? Provide a sample code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000000, 1)\n"
     ]
    }
   ],
   "source": [
    "x = datetime.datetime(1993, 12, 9, 0, 0)\n",
    "\n",
    "simulated_dates = []\n",
    "\n",
    "for i in range(2000000):\n",
    "    x += datetime.timedelta(minutes=60)\n",
    "    simulated_dates.append(x)\n",
    "\n",
    "df = pd.DataFrame(simulated_dates, columns=['Dates'])\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without multiprocessing: 16.446693420410156 seconds\n"
     ]
    }
   ],
   "source": [
    "# Function to add an hour to a given chunk of data\n",
    "def add_hour(dates):\n",
    "    return dates + pd.Timedelta(hours=1)\n",
    "\n",
    "# Without multiprocessing\n",
    "start_time = time.time()\n",
    "df['Dates'] = df['Dates'].apply(add_hour)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"Without multiprocessing:\", end_time - start_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With multiprocessing: 0.24020624160766602 seconds\n"
     ]
    }
   ],
   "source": [
    "# With multiprocessing\n",
    "def process_chunk(chunk):\n",
    "    return add_hour(chunk)\n",
    "\n",
    "start_time = time.time()\n",
    "num_cores = mp.cpu_count()\n",
    "chunk_size = len(df) // num_cores\n",
    "chunks = [df['Dates'][i:i+chunk_size] for i in range(0, len(df), chunk_size)]\n",
    "\n",
    "with mp.Pool(processes=num_cores) as pool:\n",
    "    df['Dates'] = pd.concat(pool.map(process_chunk, chunks))\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"With multiprocessing:\", end_time - start_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Write a Python script using the Azure SDK that uploads a file to an Azure Blob Storage container. Ensure the script checks if the container exists and creates it if it does not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container 'container' already exists.\n",
      "File '/home/saim/dtu_test_case/test.txt' uploaded to Azure Blob Storage as 'test_blob.txt' in container 'container'.\n"
     ]
    }
   ],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "from azure.core.exceptions import ResourceExistsError\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv('../.env')\n",
    "\n",
    "# Azure Storage account details\n",
    "connection_string = os.getenv(\"AZURE_STORAGE_CONNECTION_STRING\")\n",
    "container_name = \"container\"\n",
    "local_file_path = \"/home/saim/dtu_test_case/test.txt\"\n",
    "blob_name = \"test_blob.txt\"\n",
    "\n",
    "\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "try:\n",
    "    container_client.create_container()\n",
    "    print(f\"Container '{container_name}' created successfully.\")\n",
    "except ResourceExistsError:\n",
    "    print(f\"Container '{container_name}' already exists.\")\n",
    "\n",
    "blob_client = blob_service_client.get_blob_client(container=container_name, blob=blob_name)\n",
    "\n",
    "with open(local_file_path, \"rb\") as data:\n",
    "    blob_client.upload_blob(data, overwrite=True)\n",
    "\n",
    "print(f\"File '{local_file_path}' uploaded to Azure Blob Storage as '{blob_name}' in container '{container_name}'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Python script to download logs from Azure (e.g. events from a specific resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Downloaded logs to azure_webapp_logs.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs have been downloaded and extracted.\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import subprocess\n",
    "\n",
    "# Azure subscription and resource details\n",
    "resource_group_name = \"Zoomcamp\"\n",
    "app_name = \"my-app\"\n",
    "\n",
    "# Download the logs using Azure CLI\n",
    "command = f\"az webapp log download --resource-group {resource_group_name} --name {app_name} --log-file azure_webapp_logs.zip\"\n",
    "\n",
    "subprocess.run(command, shell=True, check=True)\n",
    "\n",
    "with zipfile.ZipFile('azure_webapp_logs.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('logs')\n",
    "\n",
    "print(\"Logs have been downloaded and extracted.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dtu_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
